{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Parse data\n",
    "Store data in NER format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "train_path = \"/datadrive/AGRR-2019/train.csv\"\n",
    "valid_path = \"/datadrive/AGRR-2019/dev.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(train_path, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "      <th>cV</th>\n",
       "      <th>cR1</th>\n",
       "      <th>cR2</th>\n",
       "      <th>V</th>\n",
       "      <th>R1</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Будучи в прошлый четверг в Софии, он назвал се...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Работа с двухбайтовыми наборами символов — про...</td>\n",
       "      <td>1</td>\n",
       "      <td>92:99</td>\n",
       "      <td>83:91</td>\n",
       "      <td>103:109</td>\n",
       "      <td>127:127</td>\n",
       "      <td>119:124</td>\n",
       "      <td>127:134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Заместитель Генерального секретаря подчеркнул,...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Продажа недвижимости из собственных портфелей ...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Новым является то, что повышенное давление кон...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  class     cV    cR1  \\\n",
       "0  Будучи в прошлый четверг в Софии, он назвал се...      0    NaN    NaN   \n",
       "1  Работа с двухбайтовыми наборами символов — про...      1  92:99  83:91   \n",
       "2  Заместитель Генерального секретаря подчеркнул,...      0    NaN    NaN   \n",
       "3  Продажа недвижимости из собственных портфелей ...      0    NaN    NaN   \n",
       "4  Новым является то, что повышенное давление кон...      0    NaN    NaN   \n",
       "\n",
       "       cR2        V       R1       R2  \n",
       "0      NaN      NaN      NaN      NaN  \n",
       "1  103:109  127:127  119:124  127:134  \n",
       "2      NaN      NaN      NaN      NaN  \n",
       "3      NaN      NaN      NaN      NaN  \n",
       "4      NaN      NaN      NaN      NaN  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sup_labels = ['cV', 'cR1', 'cR2', 'V', 'R1', 'R2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_iob( words, tag):\n",
    "    tags = []\n",
    "    if not len(words):\n",
    "        raise ValueError(\"Words should have len > 0.\")\n",
    "    tags.append(\"{}_{}\".format(\"B\", tag))\n",
    "    tags.extend([\"{}_{}\".format(\"I\", tag)] * (len(words) - 1))\n",
    "    return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_row(row, origin_idx, sup_labels=['cV', 'cR1', 'cR2', 'V', 'R1', 'R2'], word_tokenizer=lambda x: x.split()):\n",
    "    text = row.text\n",
    "    len_doc = len(text)\n",
    "    pos = 0\n",
    "    splitted = []\n",
    "    tags = []\n",
    "    cur_pos = 0\n",
    "    cls = 0\n",
    "    if isinstance(cls, (float, np.float64, np.float32, np.float, np.float128)):\n",
    "        cls = int(row[\"class\"])\n",
    "    tokens_pos = dict()\n",
    "    if cls:\n",
    "        for name in sup_labels:\n",
    "            if type(row[name]) is not float:\n",
    "                for b in row[name].split():\n",
    "                    b = b.split(\":\")\n",
    "                    start_pos, end_pos = map(int, b)\n",
    "                    tokens_pos[start_pos] = {\"name\": name, \"text\": text[start_pos:end_pos]}\n",
    "    while pos < len_doc:\n",
    "        token = tokens_pos.get(pos)\n",
    "        if token:\n",
    "            splitted.append(text[cur_pos:pos])\n",
    "            tags.append((\"O\", pos))\n",
    "            pos += len(token[\"text\"])\n",
    "            cur_pos = pos\n",
    "            splitted.append(token[\"text\"])\n",
    "            tags.append((token[\"name\"], pos))\n",
    "        pos += 1\n",
    "    if len(text[cur_pos:pos]):\n",
    "        # pos = min(len_doc, self.max_pos + 20)\n",
    "        splitted.append(text[cur_pos:pos])\n",
    "        tags.append((\"O\", cur_pos))\n",
    "    res_tokens = []\n",
    "    assert len(splitted) == len(tags)\n",
    "    cur_pos = 0\n",
    "    len_word = 0\n",
    "    res_labels = []\n",
    "    res_tokens = []\n",
    "    res_start_pos = []\n",
    "    res_len = []\n",
    "    for s_text, (tag, pos) in zip(splitted, tags):\n",
    "        words = word_tokenizer(s_text)\n",
    "        # words = self.__clean_word(text).split()\n",
    "        if not len(words):\n",
    "            continue\n",
    "        if tag == \"O\":\n",
    "            token_tags = [\"O\"] * len(words)\n",
    "        else:\n",
    "            token_tags = to_iob(words, tag)\n",
    "        assert len(words) == len(token_tags)\n",
    "        for word, tag_ in zip(words, token_tags):\n",
    "            cur_pos = text.find(word, cur_pos)\n",
    "            len_word = len(word)\n",
    "            if len(word):\n",
    "                res_labels.append(tag_)\n",
    "                res_tokens.append(word)\n",
    "                res_start_pos.append(str(cur_pos))\n",
    "                res_len.append(str(len_word))\n",
    "            cur_pos += len_word\n",
    "    return pd.DataFrame({\n",
    "        0: [\" \".join(res_labels)],\n",
    "        1: [\" \".join(res_tokens)],\n",
    "        2: [cls],\n",
    "        \"start_pos\": [\" \".join(res_start_pos)],\n",
    "        \"len\": [\" \".join(res_len)],\n",
    "        \"origin_idx\": origin_idx\n",
    "    }, columns=[0, 1, 2, \"start_pos\", \"len\", \"origin_idx\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prc_df(path, sup_labels):\n",
    "    res = pd.DataFrame(columns=[0, 1, 2, \"start_pos\", \"len\", \"origin_idx\"])\n",
    "    df = pd.read_csv(path, sep=\"\\t\")\n",
    "    for origin_idx, row in tqdm(df.iterrows(), total=len(df), leave=False):\n",
    "        res = res.append(parse_row(row, origin_idx, sup_labels))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    }
   ],
   "source": [
    "train_df = prc_df(train_path, sup_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>start_pos</th>\n",
       "      <th>len</th>\n",
       "      <th>origin_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O O O O O O O O O O O O O O O O O O O O O O O O O</td>\n",
       "      <td>Будучи в прошлый четверг в Софии, он назвал се...</td>\n",
       "      <td>0</td>\n",
       "      <td>0 7 9 17 25 27 34 37 44 49 61 82 84 87 97 102 ...</td>\n",
       "      <td>6 1 7 7 1 6 2 6 4 11 20 1 2 9 4 4 5 7 1 4 7 8 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O O O O O O O O O O O O B_cR1 I_cR1 B_cV O B_c...</td>\n",
       "      <td>Работа с двухбайтовыми наборами символов — про...</td>\n",
       "      <td>1</td>\n",
       "      <td>0 7 9 23 32 41 43 50 57 61 75 79 83 89 92 100 ...</td>\n",
       "      <td>6 1 13 8 8 1 6 6 3 13 3 3 5 2 7 2 6 6 1 5 1 2 4 1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n",
       "      <td>Заместитель Генерального секретаря подчеркнул,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0 12 25 35 47 51 60 71 74 81 97 108 110 118 12...</td>\n",
       "      <td>11 12 9 11 3 8 10 2 6 15 10 1 7 2 1 12 5 6 4 1...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O O O O O O O O O O O O O O O O O O O O O O O O</td>\n",
       "      <td>Продажа недвижимости из собственных портфелей ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0 8 21 24 36 46 56 72 76 78 87 94 97 107 109 1...</td>\n",
       "      <td>7 12 2 11 9 9 15 3 1 8 6 2 9 1 6 1 13 9 8 3 9 ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n",
       "      <td>Новым является то, что повышенное давление кон...</td>\n",
       "      <td>0</td>\n",
       "      <td>0 6 15 19 23 34 43 59 67 73 86 98 102 111 113 ...</td>\n",
       "      <td>5 8 3 3 10 8 15 7 5 12 11 3 8 1 7 5 11 9 1 15 ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  \\\n",
       "0  O O O O O O O O O O O O O O O O O O O O O O O O O   \n",
       "0  O O O O O O O O O O O O B_cR1 I_cR1 B_cV O B_c...   \n",
       "0  O O O O O O O O O O O O O O O O O O O O O O O ...   \n",
       "0    O O O O O O O O O O O O O O O O O O O O O O O O   \n",
       "0  O O O O O O O O O O O O O O O O O O O O O O O ...   \n",
       "\n",
       "                                                   1  2  \\\n",
       "0  Будучи в прошлый четверг в Софии, он назвал се...  0   \n",
       "0  Работа с двухбайтовыми наборами символов — про...  1   \n",
       "0  Заместитель Генерального секретаря подчеркнул,...  0   \n",
       "0  Продажа недвижимости из собственных портфелей ...  0   \n",
       "0  Новым является то, что повышенное давление кон...  0   \n",
       "\n",
       "                                           start_pos  \\\n",
       "0  0 7 9 17 25 27 34 37 44 49 61 82 84 87 97 102 ...   \n",
       "0  0 7 9 23 32 41 43 50 57 61 75 79 83 89 92 100 ...   \n",
       "0  0 12 25 35 47 51 60 71 74 81 97 108 110 118 12...   \n",
       "0  0 8 21 24 36 46 56 72 76 78 87 94 97 107 109 1...   \n",
       "0  0 6 15 19 23 34 43 59 67 73 86 98 102 111 113 ...   \n",
       "\n",
       "                                                 len origin_idx  \n",
       "0  6 1 7 7 1 6 2 6 4 11 20 1 2 9 4 4 5 7 1 4 7 8 ...          0  \n",
       "0  6 1 13 8 8 1 6 6 3 13 3 3 5 2 7 2 6 6 1 5 1 2 4 1          1  \n",
       "0  11 12 9 11 3 8 10 2 6 15 10 1 7 2 1 12 5 6 4 1...          2  \n",
       "0  7 12 2 11 9 9 15 3 1 8 6 2 9 1 6 1 13 9 8 3 9 ...          3  \n",
       "0  5 8 3 3 10 8 15 7 5 12 11 3 8 1 7 5 11 9 1 15 ...          4  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \r"
     ]
    }
   ],
   "source": [
    "dev_df = prc_df(valid_path, sup_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>start_pos</th>\n",
       "      <th>len</th>\n",
       "      <th>origin_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n",
       "      <td>Центральная часть лунной тени, где наблюдается...</td>\n",
       "      <td>0</td>\n",
       "      <td>0 12 18 25 31 35 47 54 59 68 77 80 86 88 99 10...</td>\n",
       "      <td>11 5 6 5 3 11 6 4 8 8 2 5 1 10 9 5 5 12 10 1 7...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O B_cV B_cR1 I_cR1 B_cR2 I_cR2 O O B_R1 I_R1 I...</td>\n",
       "      <td>Я превращу твое сердце в траву , а все, что ты...</td>\n",
       "      <td>1</td>\n",
       "      <td>0 2 11 16 23 25 30 32 34 39 43 46 52 54 56 60</td>\n",
       "      <td>1 8 4 6 1 5 1 1 4 3 2 6 1 1 4 1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O O O B_cR1 B_cV B_cR2 I_cR2 I_cR2 O O B_R1 B_...</td>\n",
       "      <td>В данном примере строки сгруппированы по назва...</td>\n",
       "      <td>1</td>\n",
       "      <td>0 2 9 17 24 38 41 50 56 58 60 68 71 81 88</td>\n",
       "      <td>1 6 7 6 13 2 8 6 1 1 7 2 9 7 1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O O O O O O O O O O O O</td>\n",
       "      <td>Ассоциация намерена занять на мировом рынке до...</td>\n",
       "      <td>0</td>\n",
       "      <td>0 11 20 27 30 38 44 50 57 63 71 79</td>\n",
       "      <td>10 8 6 2 7 5 5 6 5 7 7 14</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O O O O O O O</td>\n",
       "      <td>Ты сама все портишь-твои слова хороший мой</td>\n",
       "      <td>0</td>\n",
       "      <td>0 3 8 12 25 31 39</td>\n",
       "      <td>2 4 3 12 5 7 3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  \\\n",
       "0  O O O O O O O O O O O O O O O O O O O O O O O ...   \n",
       "0  O B_cV B_cR1 I_cR1 B_cR2 I_cR2 O O B_R1 I_R1 I...   \n",
       "0  O O O B_cR1 B_cV B_cR2 I_cR2 I_cR2 O O B_R1 B_...   \n",
       "0                            O O O O O O O O O O O O   \n",
       "0                                      O O O O O O O   \n",
       "\n",
       "                                                   1  2  \\\n",
       "0  Центральная часть лунной тени, где наблюдается...  0   \n",
       "0  Я превращу твое сердце в траву , а все, что ты...  1   \n",
       "0  В данном примере строки сгруппированы по назва...  1   \n",
       "0  Ассоциация намерена занять на мировом рынке до...  0   \n",
       "0         Ты сама все портишь-твои слова хороший мой  0   \n",
       "\n",
       "                                           start_pos  \\\n",
       "0  0 12 18 25 31 35 47 54 59 68 77 80 86 88 99 10...   \n",
       "0      0 2 11 16 23 25 30 32 34 39 43 46 52 54 56 60   \n",
       "0          0 2 9 17 24 38 41 50 56 58 60 68 71 81 88   \n",
       "0                 0 11 20 27 30 38 44 50 57 63 71 79   \n",
       "0                                  0 3 8 12 25 31 39   \n",
       "\n",
       "                                                 len origin_idx  \n",
       "0  11 5 6 5 3 11 6 4 8 8 2 5 1 10 9 5 5 12 10 1 7...          0  \n",
       "0                    1 8 4 6 1 5 1 1 4 3 2 6 1 1 4 1          1  \n",
       "0                     1 6 7 6 13 2 8 6 1 1 7 2 9 7 1          2  \n",
       "0                          10 8 6 2 7 5 5 6 5 7 7 14          3  \n",
       "0                                     2 4 3 12 5 7 3          4  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(\"/datadrive/AGRR-2019/train_parsed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df.to_csv(\"/datadrive/AGRR-2019/dev_parsed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from modules import BertNerData as NerData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "train_path = \"/datadrive/AGRR-2019/train_parsed.csv\"\n",
    "valid_path = \"/datadrive/AGRR-2019/dev_parsed.csv\"\n",
    "model_dir = \" /datadrive/models/multi_cased_L-12_H-768_A-12/\"\n",
    "init_checkpoint_pt = os.path.join(\"/datadrive/models/multi_cased_L-12_H-768_A-12/\", \"pytorch_model.bin\")\n",
    "bert_config_file = os.path.join(\"/datadrive/bert/multi_cased_L-12_H-768_A-12/\", \"bert_config.json\")\n",
    "vocab_file = os.path.join(\"/datadrive/bert/multi_cased_L-12_H-768_A-12/\", \"vocab.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = NerData.create(train_path, valid_path, vocab_file, is_cls=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<pad>': 0, '[CLS]': 1, 'B_O': 2, 'X': 3, 'B_cR1': 4, 'I_cR1': 5, 'B_cV': 6, 'B_cR2': 7, 'B_R1': 8, 'B_R2': 9, 'I_R2': 10, 'I_cR2': 11, 'I_R1': 12, 'I_cV': 13}\n"
     ]
    }
   ],
   "source": [
    "print(data.label2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.label2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create model\n",
    "For creating pytorch model we need to create `NerModel` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.models.bert_models import BertBiLSTMAttnNCRFJoint, BertBiLSTMAttnNCRF, BertBiLSTMNCRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build CRF...\n"
     ]
    }
   ],
   "source": [
    "# for 0.9\n",
    "model = BertBiLSTMAttnNCRFJoint.create(\n",
    "    len(data.label2idx), len(data.cls2idx), bert_config_file, init_checkpoint_pt,\n",
    "    enc_hidden_dim=1024, rnn_layers=1, num_heads=3, input_dropout=0.5, nbest=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AttnNCRFJointDecoder(\n",
       "  (attn): MultiHeadAttention(\n",
       "    (attention): _MultiHeadAttention(\n",
       "      (attention): ScaledDotProductAttention(\n",
       "        (softmax): Softmax()\n",
       "        (dropout): Dropout(p=0.5)\n",
       "      )\n",
       "    )\n",
       "    (proj): Linear(in_features=192, out_features=1024, bias=True)\n",
       "    (dropout): Dropout(p=0.5)\n",
       "    (layer_norm): LayerNormalization()\n",
       "  )\n",
       "  (linear): Linears(\n",
       "    (linears): ModuleList(\n",
       "      (0): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    )\n",
       "    (output_linear): Linear(in_features=512, out_features=16, bias=True)\n",
       "  )\n",
       "  (crf): NCRF()\n",
       "  (intent_out): PoolingLinearClassifier(\n",
       "    (dropout): Dropout(p=0.5)\n",
       "    (linear): Linears(\n",
       "      (linears): ModuleList(\n",
       "        (0): Linear(in_features=3072, out_features=512, bias=True)\n",
       "      )\n",
       "      (output_linear): Linear(in_features=512, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (intent_loss): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8148255"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_n_trainable_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create learner\n",
    "\n",
    "For training our pytorch model we need to create `NerLearner` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules import NerLearner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "learner = NerLearner(model, data,\n",
    "                     best_model_path=\"/datadrive/AGRR-2019/big.cpt\",\n",
    "                     lr=0.001, clip=5.0, sup_labels=data.id2label[1:],\n",
    "                     t_total=num_epochs * len(data.train_dl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Learn your NER model\n",
    "Call `learner.fit`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn_crfsuite.metrics import flat_classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-25 05:28:05,483 INFO: Resuming train... Current epoch 1.\n",
      "2019-02-25 05:36:29,881 INFO:                                                      \n",
      "epoch 2, average train epoch loss=12.336\n",
      "\n",
      "2019-02-25 05:37:26,868 INFO: on epoch 1 by max_f1: 0.949\n",
      "2019-02-25 05:37:26,869 INFO: on epoch {} classification report:\n",
      "2019-02-25 05:37:26,870 INFO: Saving new best model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      [CLS]      1.000     1.000     1.000      4142\n",
      "        B_O      0.921     0.958     0.940     74268\n",
      "          X      0.989     0.983     0.986    109877\n",
      "      B_cR1      0.726     0.571     0.639      1382\n",
      "      I_cR1      0.717     0.494     0.585      2022\n",
      "       B_cV      0.809     0.760     0.784      1382\n",
      "      B_cR2      0.761     0.681     0.719      1355\n",
      "       B_R1      0.868     0.869     0.869      1500\n",
      "       B_R2      0.849     0.857     0.853      1473\n",
      "       I_R2      0.811     0.626     0.707      3255\n",
      "      I_cR2      0.708     0.673     0.690      2395\n",
      "       I_R1      0.864     0.732     0.793      1769\n",
      "       I_cV      0.000     0.000     0.000         1\n",
      "\n",
      "avg / total      0.949     0.950     0.949    204821\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0      0.789     0.995     0.880      2760\n",
      "          1      0.979     0.469     0.634      1382\n",
      "\n",
      "avg / total      0.852     0.819     0.798      4142\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-25 05:45:58,676 INFO:                                                      \n",
      "epoch 3, average train epoch loss=6.9561\n",
      "\n",
      "2019-02-25 05:46:54,367 INFO: on epoch 2 by max_f1: 0.961\n",
      "2019-02-25 05:46:54,368 INFO: on epoch {} classification report:\n",
      "2019-02-25 05:46:54,369 INFO: Saving new best model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      [CLS]      1.000     1.000     1.000      4142\n",
      "        B_O      0.948     0.959     0.953     74268\n",
      "          X      0.985     0.994     0.989    109877\n",
      "      B_cR1      0.852     0.599     0.703      1382\n",
      "      I_cR1      0.837     0.522     0.643      2022\n",
      "       B_cV      0.902     0.790     0.843      1382\n",
      "      B_cR2      0.826     0.799     0.812      1355\n",
      "       B_R1      0.893     0.903     0.898      1500\n",
      "       B_R2      0.872     0.908     0.889      1473\n",
      "       I_R2      0.849     0.816     0.832      3255\n",
      "      I_cR2      0.822     0.746     0.782      2395\n",
      "       I_R1      0.917     0.814     0.862      1769\n",
      "       I_cV      0.000     0.000     0.000         1\n",
      "\n",
      "avg / total      0.961     0.962     0.961    204821\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0      0.775     0.999     0.873      2760\n",
      "          1      0.995     0.422     0.592      1382\n",
      "\n",
      "avg / total      0.849     0.806     0.779      4142\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-25 05:55:34,985 INFO:                                                      \n",
      "epoch 4, average train epoch loss=5.1567\n",
      "\n",
      "2019-02-25 05:56:31,253 INFO: on epoch 3 by max_f1: 0.97\n",
      "2019-02-25 05:56:31,254 INFO: on epoch {} classification report:\n",
      "2019-02-25 05:56:31,255 INFO: Saving new best model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      [CLS]      1.000     1.000     1.000      4142\n",
      "        B_O      0.965     0.962     0.963     74268\n",
      "          X      0.990     0.993     0.992    109877\n",
      "      B_cR1      0.808     0.753     0.779      1382\n",
      "      I_cR1      0.785     0.688     0.734      2022\n",
      "       B_cV      0.862     0.922     0.891      1382\n",
      "      B_cR2      0.837     0.859     0.848      1355\n",
      "       B_R1      0.898     0.936     0.916      1500\n",
      "       B_R2      0.893     0.935     0.913      1473\n",
      "       I_R2      0.879     0.879     0.879      3255\n",
      "      I_cR2      0.807     0.846     0.826      2395\n",
      "       I_R1      0.924     0.874     0.898      1769\n",
      "       I_cV      0.000     0.000     0.000         1\n",
      "\n",
      "avg / total      0.970     0.971     0.970    204821\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0      0.850     0.998     0.918      2760\n",
      "          1      0.993     0.648     0.784      1382\n",
      "\n",
      "avg / total      0.898     0.881     0.873      4142\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-25 06:05:04,251 INFO:                                                     \n",
      "epoch 5, average train epoch loss=4.1059\n",
      "\n",
      "2019-02-25 06:05:59,580 INFO: on epoch 3 by max_f1: 0.97\n",
      "2019-02-25 06:05:59,581 INFO: on epoch {} classification report:\n",
      "  0%|          | 0/1026 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      [CLS]      1.000     1.000     1.000      4142\n",
      "        B_O      0.974     0.951     0.962     74268\n",
      "          X      0.993     0.990     0.992    109877\n",
      "      B_cR1      0.777     0.815     0.795      1382\n",
      "      I_cR1      0.676     0.846     0.751      2022\n",
      "       B_cV      0.876     0.949     0.911      1382\n",
      "      B_cR2      0.839     0.869     0.854      1355\n",
      "       B_R1      0.912     0.928     0.920      1500\n",
      "       B_R2      0.905     0.942     0.923      1473\n",
      "       I_R2      0.815     0.936     0.872      3255\n",
      "      I_cR2      0.739     0.937     0.827      2395\n",
      "       I_R1      0.852     0.928     0.888      1769\n",
      "       I_cV      0.000     0.000     0.000         1\n",
      "\n",
      "avg / total      0.972     0.970     0.970    204821\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0      0.959     0.980     0.969      2760\n",
      "          1      0.958     0.917     0.937      1382\n",
      "\n",
      "avg / total      0.959     0.959     0.958      4142\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-25 06:14:26,323 INFO:                                                      \n",
      "epoch 6, average train epoch loss=3.3608\n",
      "\n",
      "2019-02-25 06:15:17,202 INFO: on epoch 5 by max_f1: 0.974\n",
      "2019-02-25 06:15:17,203 INFO: on epoch {} classification report:\n",
      "2019-02-25 06:15:17,203 INFO: Saving new best model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      [CLS]      1.000     1.000     1.000      4142\n",
      "        B_O      0.964     0.972     0.968     74268\n",
      "          X      0.995     0.990     0.992    109877\n",
      "      B_cR1      0.817     0.783     0.800      1382\n",
      "      I_cR1      0.809     0.772     0.790      2022\n",
      "       B_cV      0.876     0.957     0.915      1382\n",
      "      B_cR2      0.862     0.861     0.862      1355\n",
      "       B_R1      0.922     0.923     0.922      1500\n",
      "       B_R2      0.911     0.943     0.927      1473\n",
      "       I_R2      0.891     0.914     0.903      3255\n",
      "      I_cR2      0.853     0.838     0.845      2395\n",
      "       I_R1      0.944     0.841     0.889      1769\n",
      "       I_cV      0.000     0.000     0.000         1\n",
      "\n",
      "avg / total      0.974     0.974     0.974    204821\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0      0.960     0.985     0.972      2760\n",
      "          1      0.968     0.918     0.942      1382\n",
      "\n",
      "avg / total      0.962     0.962     0.962      4142\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-25 06:23:59,292 INFO:                                                      \n",
      "epoch 7, average train epoch loss=2.9361\n",
      "\n",
      "2019-02-25 06:24:50,833 INFO: on epoch 6 by max_f1: 0.976\n",
      "2019-02-25 06:24:50,834 INFO: on epoch {} classification report:\n",
      "2019-02-25 06:24:50,834 INFO: Saving new best model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      [CLS]      1.000     1.000     1.000      4142\n",
      "        B_O      0.964     0.976     0.970     74268\n",
      "          X      0.994     0.991     0.993    109877\n",
      "      B_cR1      0.821     0.842     0.831      1382\n",
      "      I_cR1      0.775     0.831     0.802      2022\n",
      "       B_cV      0.943     0.905     0.924      1382\n",
      "      B_cR2      0.898     0.838     0.867      1355\n",
      "       B_R1      0.940     0.926     0.933      1500\n",
      "       B_R2      0.907     0.939     0.923      1473\n",
      "       I_R2      0.933     0.861     0.896      3255\n",
      "      I_cR2      0.880     0.824     0.851      2395\n",
      "       I_R1      0.962     0.859     0.907      1769\n",
      "       I_cV      0.000     0.000     0.000         1\n",
      "\n",
      "avg / total      0.976     0.976     0.976    204821\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0      0.961     0.991     0.976      2760\n",
      "          1      0.981     0.920     0.950      1382\n",
      "\n",
      "avg / total      0.968     0.967     0.967      4142\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-25 06:33:35,156 INFO:                                                      \n",
      "epoch 8, average train epoch loss=2.7444\n",
      "\n",
      "2019-02-25 06:34:26,910 INFO: on epoch 6 by max_f1: 0.976\n",
      "2019-02-25 06:34:26,911 INFO: on epoch {} classification report:\n",
      "  0%|          | 0/1026 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      [CLS]      1.000     1.000     1.000      4142\n",
      "        B_O      0.971     0.971     0.971     74268\n",
      "          X      0.992     0.993     0.993    109877\n",
      "      B_cR1      0.862     0.812     0.836      1382\n",
      "      I_cR1      0.751     0.867     0.805      2022\n",
      "       B_cV      0.963     0.894     0.927      1382\n",
      "      B_cR2      0.892     0.856     0.874      1355\n",
      "       B_R1      0.944     0.917     0.930      1500\n",
      "       B_R2      0.937     0.924     0.930      1473\n",
      "       I_R2      0.915     0.906     0.910      3255\n",
      "      I_cR2      0.874     0.863     0.869      2395\n",
      "       I_R1      0.912     0.918     0.915      1769\n",
      "       I_cV      0.000     0.000     0.000         1\n",
      "\n",
      "avg / total      0.977     0.976     0.976    204821\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0      0.961     0.989     0.975      2760\n",
      "          1      0.976     0.920     0.947      1382\n",
      "\n",
      "avg / total      0.966     0.966     0.965      4142\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 2.3024029034573035:  32%|███▏      | 333/1026 [02:49<05:52,  1.97it/s]"
     ]
    }
   ],
   "source": [
    "learner.fit(num_epochs, target_metric='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(learner.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Evaluate\n",
    "Create new data loader from existing path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.data.bert_data import get_bert_data_loader_for_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dl = get_bert_data_loader_for_predict(valid_path, learner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preds_res, preds_cls = learner.predict(dl)\n",
    "# preds_res = learner.predict(dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IOB precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from modules.train.train import validate_step\n",
    "p_rep, p_cls = validate_step(\n",
    "    learner.data.valid_dl, learner.model, learner.data.id2label, learner.data.id2label[1:], learner.data.cls2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      [CLS]      1.000     1.000     1.000      4142\n",
      "        B_O      0.976     0.975     0.975     74268\n",
      "          X      0.993     0.993     0.993    109877\n",
      "      B_cR1      0.860     0.851     0.855      1382\n",
      "      I_cR1      0.855     0.857     0.856      2022\n",
      "       B_cV      0.956     0.937     0.946      1382\n",
      "      B_cR2      0.893     0.895     0.894      1355\n",
      "       B_R1      0.946     0.923     0.935      1500\n",
      "       B_R2      0.933     0.948     0.940      1473\n",
      "       I_R2      0.932     0.911     0.922      3255\n",
      "      I_cR2      0.858     0.921     0.888      2395\n",
      "       I_R1      0.915     0.922     0.919      1769\n",
      "       I_cV      0.000     0.000     0.000         1\n",
      "\n",
      "avg / total      0.980     0.980     0.980    204821\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(p_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0      0.887     0.999     0.940      2760\n",
      "          1      0.998     0.745     0.853      1382\n",
      "\n",
      "avg / total      0.924     0.915     0.911      4142\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(p_cls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokens report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn_crfsuite.metrics import flat_classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.utils.utils import bert_labels2tokens, first_choicer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_tokens, pred_labels = bert_labels2tokens(dl, preds_res, first_choicer)\n",
    "true_tokens, true_labels = bert_labels2tokens(dl, [x.labels for x in dl.dataset], first_choicer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert pred_tokens == true_tokens\n",
    "tokens_report = flat_classification_report(true_labels, pred_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### By tokens reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9704301667364155, 0.8328229828166069)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "pl = []\n",
    "for line in pred_labels:\n",
    "    for p in line:\n",
    "        pl.append(p)\n",
    "        \n",
    "tl = []\n",
    "for line in true_labels:\n",
    "    for p in line:\n",
    "        tl.append(p)\n",
    "accuracy_score(tl, pl), f1_score(tl, pl, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        B_O       0.98      0.98      0.98     74268\n",
      "       B_R1       0.95      0.92      0.94      1500\n",
      "       B_R2       0.94      0.95      0.94      1473\n",
      "      B_cR1       0.86      0.85      0.86      1382\n",
      "      B_cR2       0.89      0.90      0.89      1355\n",
      "       B_cV       0.96      0.94      0.95      1382\n",
      "       I_R1       0.93      0.92      0.93      1769\n",
      "       I_R2       0.94      0.91      0.93      3255\n",
      "      I_cR1       0.86      0.86      0.86      2022\n",
      "      I_cR2       0.87      0.92      0.89      2395\n",
      "       I_cV       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.97      0.97      0.97     90802\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tokens_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. To needle format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens2spans_(tokens_, labels_, start_pos):\n",
    "    pos_idx = 0\n",
    "    res = []\n",
    "    idx_ = 0\n",
    "    while idx_ < len(labels_):\n",
    "        label = labels_[idx_]\n",
    "        if label in [\"I_O\", \"B_O\", \"O\"]:\n",
    "            res.append((tokens_[idx_], \"O\", None))\n",
    "            idx_ += 1\n",
    "        elif label == \"[SEP]\" or label == \"<eos>\":\n",
    "            break\n",
    "        elif label == \"[CLS]\" or label == \"<bos>\":\n",
    "            res.append((tokens_[idx_], label, start_pos[idx_]))\n",
    "            idx_ += 1\n",
    "        else:\n",
    "            span = [tokens_[idx_]]\n",
    "            \n",
    "            try:\n",
    "                pos = start_pos[idx_]\n",
    "            except:\n",
    "                print(\" \".join(tokens_))\n",
    "                print(\" \".join(labels_))\n",
    "                print(tokens_[idx_], labels_[idx_])\n",
    "                print(start_pos[idx_])\n",
    "            try:\n",
    "                span_label = labels_[idx_].split(\"_\")[1]\n",
    "            except IndexError:\n",
    "                print(label, labels_[idx_].split(\"_\"))\n",
    "                span_label = None\n",
    "            idx_ += 1\n",
    "            while idx_ < len(labels_):\n",
    "                if labels_[idx_] not in [\"I_O\", \"B_O\", \"O\"] and labels_[idx_].split(\"_\")[0] == \"I\" and  span_label == labels_[idx_].split(\"_\")[1]:\n",
    "                    span.append(tokens_[idx_])\n",
    "                    idx_ += 1\n",
    "                # Skip one O\n",
    "                elif idx_ + 1 < len(labels_) and labels_[idx_ + 1] not in [\"I_O\", \"B_O\", \"O\"] and labels_[idx_ + 1].split(\"_\")[0] == \"I\" and  span_label == labels_[idx_ + 1].split(\"_\")[1]:\n",
    "                    span.append(tokens_[idx_])\n",
    "                    idx_ += 1\n",
    "                    span.append(tokens_[idx_])\n",
    "                    idx_ += 1\n",
    "                else:\n",
    "                    break\n",
    "            res.append((\" \".join(span), span_label, pos))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_prc_row(text, tokens, labels, cls, start_pos):\n",
    "    # SHIT IN DATASET, fix align\n",
    "    text = text.replace('\\x97', \"U\")\n",
    "    text = text.replace('\\uf076', \"U\")\n",
    "    text = text.replace(\"\\ue405\", \"U\")\n",
    "    text = text.replace(\"\\ue105\", \"U\")\n",
    "    text = text.replace(\"\\ue415\", \"U\")\n",
    "    text = text.replace('\\x07', \"U\")\n",
    "    start_pos = []\n",
    "    pos = 0\n",
    "    for tok in tokens:\n",
    "        if tok.find(\"unk\") > -1:\n",
    "            tok = tok.replace(\"unk\", \"U\")\n",
    "        pos = text.find(tok, max(pos-2, 0))\n",
    "        # SHIT IN DATASET, fix align\n",
    "        if pos == -1:\n",
    "            text = text.replace(\"unk\", \"UUU\")\n",
    "            tok = \"UUU\"\n",
    "            print(tok)\n",
    "        start_pos.append(pos)\n",
    "    spans = tokens2spans_(tokens, labels, start_pos)\n",
    "    res = {}\n",
    "    cls = 0\n",
    "    for token, label, pos in spans:\n",
    "        if label != \"O\":\n",
    "            cls = 1\n",
    "            pos = int(pos)\n",
    "            if label in res:\n",
    "                if tok.find(\"unk\") > -1:\n",
    "                    tok = tok.replace(\"unk\", \"U\")\n",
    "                pp = pos\n",
    "                pos = text.find(token, max(pos-1, 0))\n",
    "                if pos == -1:\n",
    "                    print(pp, text[pp:], token, text[pp:].find(token))\n",
    "                    pos = pp\n",
    "                res[label] += \" \" + \":\".join(map(str, [pos, pos + len(token)]))\n",
    "                if label == \"R2\":\n",
    "                    res[\"V\"] += \" \" + \":\".join(map(str, [pos, pos]))\n",
    "            else:\n",
    "                res[label] = \":\".join(map(str, [pos, pos + len(token)]))\n",
    "                if label == \"R2\":\n",
    "                    res[\"V\"] = \":\".join(map(str, [pos, pos]))\n",
    "    if res.get(\"R1\") and res.get(\"R2\", None) is None:\n",
    "        try:\n",
    "            res[\"V\"] = \" \".join([\"{}:{}\".format(f.split(\":\")[0], f.split(\":\")[0]) for f in res.get(\"R1\").split()])\n",
    "        except:\n",
    "            print(res.get(\"R1\"), res.get(\"R1\").split(), )\n",
    "            raise\n",
    "    res[\"text\"] = text\n",
    "    res[\"class\"] = cls\n",
    "    for key in res:\n",
    "        res[key] = [res[key]]\n",
    "    return pd.DataFrame(res, columns=['text', 'class', 'cV', 'cR1', 'cR2', 'V', 'R1', 'R2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_prc(origin_path, parsed_path, pred_tokens, pred_labels, pred_cls):\n",
    "    origin_df = pd.read_csv(origin_path, sep=\"\\t\")\n",
    "    parsed_df = pd.read_csv(parsed_path)\n",
    "    res = pd.DataFrame(columns=['text', 'class', 'cV', 'cR1', 'cR2', 'V', 'R1', 'R2'])\n",
    "    idx = 0\n",
    "    for (_, o_row), (_, p_row), tokens, labels, cls in zip(origin_df.iterrows(), parsed_df.iterrows(), pred_tokens, pred_labels, pred_cls):\n",
    "        try:\n",
    "            res = res.append(post_prc_row(o_row.text, tokens, labels, cls, p_row.start_pos.split()))\n",
    "        except:\n",
    "            print(o_row.text)\n",
    "            print(\" \".join(tokens))\n",
    "            print(len(p_row.start_pos.split()), len(tokens))\n",
    "            print(idx)\n",
    "            raise\n",
    "        idx += 1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_pred = post_prc(\n",
    "    \"/datadrive/AGRR-2019/dev.csv\",\n",
    "    \"/datadrive/AGRR-2019/dev_parsed.csv\",\n",
    "    pred_tokens, pred_labels, preds_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "      <th>cV</th>\n",
       "      <th>cR1</th>\n",
       "      <th>cR2</th>\n",
       "      <th>V</th>\n",
       "      <th>R1</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Центральная часть лунной тени, где наблюдается...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Я превращу твое сердце в траву, а все, что ты ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2:10</td>\n",
       "      <td>11:22</td>\n",
       "      <td>23:30</td>\n",
       "      <td>54:54</td>\n",
       "      <td>34:52</td>\n",
       "      <td>54:60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>В данном примере строки сгруппированы по назва...</td>\n",
       "      <td>1</td>\n",
       "      <td>24:37</td>\n",
       "      <td>17:23</td>\n",
       "      <td>38:56</td>\n",
       "      <td>68:68</td>\n",
       "      <td>60:67</td>\n",
       "      <td>68:88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ассоциация намерена занять на мировом рынке до...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ты сама все портишь-твои слова хороший мой</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text class     cV    cR1  \\\n",
       "0  Центральная часть лунной тени, где наблюдается...     0    NaN    NaN   \n",
       "0  Я превращу твое сердце в траву, а все, что ты ...     1   2:10  11:22   \n",
       "0  В данном примере строки сгруппированы по назва...     1  24:37  17:23   \n",
       "0  Ассоциация намерена занять на мировом рынке до...     0    NaN    NaN   \n",
       "0         Ты сама все портишь-твои слова хороший мой     0    NaN    NaN   \n",
       "\n",
       "     cR2      V     R1     R2  \n",
       "0    NaN    NaN    NaN    NaN  \n",
       "0  23:30  54:54  34:52  54:60  \n",
       "0  38:56  68:68  60:67  68:88  \n",
       "0    NaN    NaN    NaN    NaN  \n",
       "0    NaN    NaN    NaN    NaN  "
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_pred.to_csv(\"/datadrive/AGRR-2019/dev_pred.csv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary classification quality (f1-score): 0.9583778014941302\r\n",
      "Gapping resolution quality (symbol-wise f-measure): 0.9576077060524616\r\n"
     ]
    }
   ],
   "source": [
    "!python3 /datadrive/AGRR-2019/agrr_metrics.py -r /datadrive/AGRR-2019/dev.csv /datadrive/AGRR-2019/dev_pred.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = \"/datadrive/AGRR-2019/test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_df = prc_df(test_path, sup_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv(\"/datadrive/AGRR-2019/test_parsed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.data.bert_data import get_bert_data_loader_for_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dl = get_bert_data_loader_for_predict(\"/datadrive/AGRR-2019/test_parsed.csv\", learner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preds_res, preds_cls = learner.predict(dl)\n",
    "# preds_res = learner.predict(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.utils.utils import bert_labels2tokens, first_choicer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_tokens, pred_labels = bert_labels2tokens(dl, preds_res, first_choicer)\n",
    "true_tokens, true_labels = bert_labels2tokens(dl, [x.labels for x in dl.dataset], first_choicer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### See wtf encoding or spaces :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167 1 890 989 (один миллион восемьсот девяносто тысяч девятьсот восемьдесят девять) рублей 09 копеек, в том числе НДС (18 %) – 288 455 (двести восемьдесят восемь тысяч четыреста пятьдесят пять) рублей 96 копеек. 1 890 989 (один миллион -1\n",
      "UUU\n",
      "87 О  log  n   — «довольно дешево». О log n -1\n",
      "277 1997 г. – 41). 1997 г. -1\n",
      "227 относительно соответствующих месяцев 1997 г. достигло 30%, а в декабре — 40%. относительно соответствующих месяцев 1997 г. -1\n"
     ]
    }
   ],
   "source": [
    "test_pred = post_prc(\n",
    "    \"/datadrive/AGRR-2019/test.csv\",\n",
    "    \"/datadrive/AGRR-2019/test_parsed.csv\",\n",
    "    pred_tokens, pred_labels, preds_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "      <th>cV</th>\n",
       "      <th>cR1</th>\n",
       "      <th>cR2</th>\n",
       "      <th>V</th>\n",
       "      <th>R1</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>В РП и торцевой стенке, расположенной со сторо...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Диаграммы каротажа сопротивлений помогают в вы...</td>\n",
       "      <td>1</td>\n",
       "      <td>33:41</td>\n",
       "      <td>0:32</td>\n",
       "      <td>42:91</td>\n",
       "      <td>142:142</td>\n",
       "      <td>94:139</td>\n",
       "      <td>142:167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>При оценке структуры в тенговом эквиваленте 99...</td>\n",
       "      <td>1</td>\n",
       "      <td>89:99</td>\n",
       "      <td>44:88</td>\n",
       "      <td>100:107</td>\n",
       "      <td>123:123 149:149</td>\n",
       "      <td>108:122 133:146</td>\n",
       "      <td>123:130 149:156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ты самый лучший во всём Мироздании и я люблю т...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Способ позволяет ликвидировать обострение забо...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text class     cV    cR1  \\\n",
       "0  В РП и торцевой стенке, расположенной со сторо...     0    NaN    NaN   \n",
       "0  Диаграммы каротажа сопротивлений помогают в вы...     1  33:41   0:32   \n",
       "0  При оценке структуры в тенговом эквиваленте 99...     1  89:99  44:88   \n",
       "0  Ты самый лучший во всём Мироздании и я люблю т...     0    NaN    NaN   \n",
       "0  Способ позволяет ликвидировать обострение забо...     0    NaN    NaN   \n",
       "\n",
       "       cR2                V               R1               R2  \n",
       "0      NaN              NaN              NaN              NaN  \n",
       "0    42:91          142:142           94:139          142:167  \n",
       "0  100:107  123:123 149:149  108:122 133:146  123:130 149:156  \n",
       "0      NaN              NaN              NaN              NaN  \n",
       "0      NaN              NaN              NaN              NaN  "
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred.to_csv(\"/datadrive/AGRR-2019/test_pred.csv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Merge train and dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"/datadrive/AGRR-2019/train_parsed.csv\"\n",
    "valid_path = \"/datadrive/AGRR-2019/dev_parsed.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(train_path)\n",
    "dev_df = pd.read_csv(valid_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "ful_df = train_df.append(dev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20548"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ful_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "ful_df.to_csv(\"/datadrive/AGRR-2019/train_dev_parsed.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Train full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from modules import BertNerData as NerData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "train_path = \"/datadrive/AGRR-2019/train_dev_parsed.csv\"\n",
    "valid_path = \"/datadrive/AGRR-2019/dev_parsed.csv\"\n",
    "model_dir = \" /datadrive/models/multi_cased_L-12_H-768_A-12/\"\n",
    "init_checkpoint_pt = os.path.join(\"/datadrive/models/multi_cased_L-12_H-768_A-12/\", \"pytorch_model.bin\")\n",
    "bert_config_file = os.path.join(\"/datadrive/bert/multi_cased_L-12_H-768_A-12/\", \"bert_config.json\")\n",
    "vocab_file = os.path.join(\"/datadrive/bert/multi_cased_L-12_H-768_A-12/\", \"vocab.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = NerData.create(train_path, valid_path, vocab_file, is_cls=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<pad>': 0, '[CLS]': 1, 'B_O': 2, 'X': 3, 'B_cR1': 4, 'I_cR1': 5, 'B_cV': 6, 'B_cR2': 7, 'B_R1': 8, 'B_R2': 9, 'I_R2': 10, 'I_cR2': 11, 'I_R1': 12, 'I_cV': 13}\n"
     ]
    }
   ],
   "source": [
    "print(data.label2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.label2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2. Create model\n",
    "For creating pytorch model we need to create `NerModel` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.models.bert_models import BertBiLSTMAttnNCRFJoint, BertBiLSTMAttnNCRF, BertBiLSTMNCRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build CRF...\n"
     ]
    }
   ],
   "source": [
    "# for 0.9\n",
    "model = BertBiLSTMAttnNCRFJoint.create(\n",
    "    len(data.label2idx), len(data.cls2idx), bert_config_file, init_checkpoint_pt,\n",
    "    enc_hidden_dim=1024, rnn_layers=1, num_heads=3, input_dropout=0.5, nbest=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AttnNCRFJointDecoder(\n",
       "  (attn): MultiHeadAttention(\n",
       "    (attention): _MultiHeadAttention(\n",
       "      (attention): ScaledDotProductAttention(\n",
       "        (softmax): Softmax()\n",
       "        (dropout): Dropout(p=0.5)\n",
       "      )\n",
       "    )\n",
       "    (proj): Linear(in_features=192, out_features=1024, bias=True)\n",
       "    (dropout): Dropout(p=0.5)\n",
       "    (layer_norm): LayerNormalization()\n",
       "  )\n",
       "  (linear): Linears(\n",
       "    (linears): ModuleList(\n",
       "      (0): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    )\n",
       "    (output_linear): Linear(in_features=512, out_features=16, bias=True)\n",
       "  )\n",
       "  (crf): NCRF()\n",
       "  (intent_out): PoolingLinearClassifier(\n",
       "    (dropout): Dropout(p=0.5)\n",
       "    (linear): Linears(\n",
       "      (linears): ModuleList(\n",
       "        (0): Linear(in_features=3072, out_features=512, bias=True)\n",
       "      )\n",
       "      (output_linear): Linear(in_features=512, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (intent_loss): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8148255"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_n_trainable_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.3. Create learner\n",
    "\n",
    "For training our pytorch model we need to create `NerLearner` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules import NerLearner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "learner = NerLearner(model, data,\n",
    "                     best_model_path=\"/datadrive/AGRR-2019/big_full.cpt\",\n",
    "                     lr=0.001, clip=5.0, sup_labels=data.id2label[1:],\n",
    "                     t_total=num_epochs * len(data.train_dl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.4. Learn your NER model\n",
    "Call `learner.fit`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learner.fit(num_epochs, target_metric='f1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to overfit :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.data.bert_data import get_bert_data_loader_for_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dl = get_bert_data_loader_for_predict(valid_path, learner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preds_res, preds_cls = learner.predict(dl)\n",
    "# preds_res = learner.predict(dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IOB precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from modules.train.train import validate_step\n",
    "p_rep, p_cls = validate_step(\n",
    "    learner.data.valid_dl, learner.model, learner.data.id2label, learner.data.id2label[1:], learner.data.cls2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      [CLS]      1.000     1.000     1.000      4142\n",
      "        B_O      1.000     1.000     1.000     74268\n",
      "          X      1.000     1.000     1.000    109877\n",
      "      B_cR1      0.999     0.999     0.999      1382\n",
      "      I_cR1      1.000     1.000     1.000      2022\n",
      "       B_cV      1.000     1.000     1.000      1382\n",
      "      B_cR2      1.000     0.999     1.000      1355\n",
      "       B_R1      1.000     1.000     1.000      1500\n",
      "       B_R2      1.000     1.000     1.000      1473\n",
      "       I_R2      1.000     1.000     1.000      3255\n",
      "      I_cR2      1.000     1.000     1.000      2395\n",
      "       I_R1      1.000     1.000     1.000      1769\n",
      "       I_cV      1.000     1.000     1.000         1\n",
      "\n",
      "avg / total      1.000     1.000     1.000    204821\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(p_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0      1.000     1.000     1.000      2760\n",
      "          1      1.000     1.000     1.000      1382\n",
      "\n",
      "avg / total      1.000     1.000     1.000      4142\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(p_cls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokens report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn_crfsuite.metrics import flat_classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.utils.utils import bert_labels2tokens, first_choicer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_tokens, pred_labels = bert_labels2tokens(dl, preds_res, first_choicer)\n",
    "true_tokens, true_labels = bert_labels2tokens(dl, [x.labels for x in dl.dataset], first_choicer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert pred_tokens == true_tokens\n",
    "tokens_report = flat_classification_report(true_labels, pred_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### By tokens reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9999669610801524, 0.9998804619684648)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "pl = []\n",
    "for line in pred_labels:\n",
    "    for p in line:\n",
    "        pl.append(p)\n",
    "        \n",
    "tl = []\n",
    "for line in true_labels:\n",
    "    for p in line:\n",
    "        tl.append(p)\n",
    "accuracy_score(tl, pl), f1_score(tl, pl, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        B_O       1.00      1.00      1.00     74268\n",
      "       B_R1       1.00      1.00      1.00      1500\n",
      "       B_R2       1.00      1.00      1.00      1473\n",
      "      B_cR1       1.00      1.00      1.00      1382\n",
      "      B_cR2       1.00      1.00      1.00      1355\n",
      "       B_cV       1.00      1.00      1.00      1382\n",
      "       I_R1       1.00      1.00      1.00      1769\n",
      "       I_R2       1.00      1.00      1.00      3255\n",
      "      I_cR1       1.00      1.00      1.00      2022\n",
      "      I_cR2       1.00      1.00      1.00      2395\n",
      "       I_cV       1.00      1.00      1.00         1\n",
      "\n",
      "avg / total       1.00      1.00      1.00     90802\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tokens_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_pred = post_prc(\n",
    "    \"/datadrive/AGRR-2019/dev.csv\",\n",
    "    \"/datadrive/AGRR-2019/dev_parsed.csv\",\n",
    "    pred_tokens, pred_labels, preds_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "      <th>cV</th>\n",
       "      <th>cR1</th>\n",
       "      <th>cR2</th>\n",
       "      <th>V</th>\n",
       "      <th>R1</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Центральная часть лунной тени, где наблюдается...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Я превращу твое сердце в траву, а все, что ты ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2:10</td>\n",
       "      <td>11:22</td>\n",
       "      <td>23:30</td>\n",
       "      <td>54:54</td>\n",
       "      <td>34:52</td>\n",
       "      <td>54:60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>В данном примере строки сгруппированы по назва...</td>\n",
       "      <td>1</td>\n",
       "      <td>24:37</td>\n",
       "      <td>17:23</td>\n",
       "      <td>38:56</td>\n",
       "      <td>68:68</td>\n",
       "      <td>60:67</td>\n",
       "      <td>68:88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ассоциация намерена занять на мировом рынке до...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ты сама все портишь-твои слова хороший мой</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text class     cV    cR1  \\\n",
       "0  Центральная часть лунной тени, где наблюдается...     0    NaN    NaN   \n",
       "0  Я превращу твое сердце в траву, а все, что ты ...     1   2:10  11:22   \n",
       "0  В данном примере строки сгруппированы по назва...     1  24:37  17:23   \n",
       "0  Ассоциация намерена занять на мировом рынке до...     0    NaN    NaN   \n",
       "0         Ты сама все портишь-твои слова хороший мой     0    NaN    NaN   \n",
       "\n",
       "     cR2      V     R1     R2  \n",
       "0    NaN    NaN    NaN    NaN  \n",
       "0  23:30  54:54  34:52  54:60  \n",
       "0  38:56  68:68  60:67  68:88  \n",
       "0    NaN    NaN    NaN    NaN  \n",
       "0    NaN    NaN    NaN    NaN  "
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_pred.to_csv(\"/datadrive/AGRR-2019/dev_pred_overfit.csv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WTF -> errors with spaces or so on?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary classification quality (f1-score): 1.0\r\n",
      "Gapping resolution quality (symbol-wise f-measure): 0.9982856495331368\r\n"
     ]
    }
   ],
   "source": [
    "!python3 /datadrive/AGRR-2019/agrr_metrics.py -r /datadrive/AGRR-2019/dev.csv /datadrive/AGRR-2019/dev_pred_overfit.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.5 Make prediction with model trained on full data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.data.bert_data import get_bert_data_loader_for_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dl = get_bert_data_loader_for_predict(\"/datadrive/AGRR-2019/test_parsed.csv\", learner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preds_res, preds_cls = learner.predict(dl)\n",
    "# preds_res = learner.predict(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.utils.utils import bert_labels2tokens, first_choicer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_tokens, pred_labels = bert_labels2tokens(dl, preds_res, first_choicer)\n",
    "true_tokens, true_labels = bert_labels2tokens(dl, [x.labels for x in dl.dataset], first_choicer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### See wtf encoding or spaces :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163 т в  год. т в год. -1\n",
      "UUU\n",
      "87 О  log  n   — «довольно дешево». О log n -1\n",
      "277 1997 г. – 41). 1997 г. -1\n"
     ]
    }
   ],
   "source": [
    "test_pred = post_prc(\n",
    "    \"/datadrive/AGRR-2019/test.csv\",\n",
    "    \"/datadrive/AGRR-2019/test_parsed.csv\",\n",
    "    pred_tokens, pred_labels, preds_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "      <th>cV</th>\n",
       "      <th>cR1</th>\n",
       "      <th>cR2</th>\n",
       "      <th>V</th>\n",
       "      <th>R1</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>В РП и торцевой стенке, расположенной со сторо...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Диаграммы каротажа сопротивлений помогают в вы...</td>\n",
       "      <td>1</td>\n",
       "      <td>33:41</td>\n",
       "      <td>0:32</td>\n",
       "      <td>42:91</td>\n",
       "      <td>142:142</td>\n",
       "      <td>94:139</td>\n",
       "      <td>142:167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>При оценке структуры в тенговом эквиваленте 99...</td>\n",
       "      <td>1</td>\n",
       "      <td>89:99</td>\n",
       "      <td>44:88</td>\n",
       "      <td>100:107</td>\n",
       "      <td>123:123 149:149</td>\n",
       "      <td>108:122 133:146</td>\n",
       "      <td>123:130 149:156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ты самый лучший во всём Мироздании и я люблю т...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Способ позволяет ликвидировать обострение забо...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text class     cV    cR1  \\\n",
       "0  В РП и торцевой стенке, расположенной со сторо...     0    NaN    NaN   \n",
       "0  Диаграммы каротажа сопротивлений помогают в вы...     1  33:41   0:32   \n",
       "0  При оценке структуры в тенговом эквиваленте 99...     1  89:99  44:88   \n",
       "0  Ты самый лучший во всём Мироздании и я люблю т...     0    NaN    NaN   \n",
       "0  Способ позволяет ликвидировать обострение забо...     0    NaN    NaN   \n",
       "\n",
       "       cR2                V               R1               R2  \n",
       "0      NaN              NaN              NaN              NaN  \n",
       "0    42:91          142:142           94:139          142:167  \n",
       "0  100:107  123:123 149:149  108:122 133:146  123:130 149:156  \n",
       "0      NaN              NaN              NaN              NaN  \n",
       "0      NaN              NaN              NaN              NaN  "
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred.to_csv(\"/datadrive/AGRR-2019/test_pred_full.csv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
